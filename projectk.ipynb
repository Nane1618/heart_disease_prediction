{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Documents\\project\\heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers using the IQR method\n",
    "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_columns:\n",
    "    Q1 = X_train[col].quantile(0.25)\n",
    "    Q3 = X_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap the outliers\n",
    "X_train[col] = np.where(X_train[col] < lower_bound, lower_bound, X_train[col])\n",
    "X_train[col] = np.where(X_train[col] > upper_bound, upper_bound, X_train[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on categorical features\n",
    "categorical_columns = ['cp', 'restecg', 'slope', 'thal', 'ca']  # Adjust as necessary\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the categorical columns in the training data\n",
    "encoded_categorical_train = encoder.fit_transform(X_train[categorical_columns])\n",
    "\n",
    "# Transform the categorical columns in the test data\n",
    "encoded_categorical_test = encoder.transform(X_test[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the categorical columns with the encoded ones\n",
    "X_train_encoded = np.hstack([X_train.drop(columns=categorical_columns).values, encoded_categorical_train])\n",
    "X_test_encoded = np.hstack([X_test.drop(columns=categorical_columns).values, encoded_categorical_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "train_data = pd.DataFrame(X_train_scaled)\n",
    "test_data = pd.DataFrame(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0        1         2         3         4         5         6   \\\n",
      "0  1.610480 -1.46385  0.461840 -0.123235 -0.404304  0.039942 -0.715891   \n",
      "1  1.282051  0.68313  1.575595  0.023366 -0.404304 -1.373486  1.396861   \n",
      "2  0.077810 -1.46385 -0.206413 -0.835301 -0.404304 -0.917541  1.396861   \n",
      "3  0.296763  0.68313 -1.208792  1.887302 -0.404304 -0.324813  1.396861   \n",
      "4  1.829433 -1.46385 -1.208792  0.421285  2.473388 -0.917541 -0.715891   \n",
      "\n",
      "         7         8         9   ...        12        13        14        15  \\\n",
      "0  0.604853 -0.451642 -0.644364  ... -0.129641 -0.897758  1.033623 -0.247797   \n",
      "1 -0.890458  2.214145 -0.644364  ... -0.129641  1.113885 -0.967471  4.035556   \n",
      "2  0.770998 -0.451642 -0.644364  ...  7.713624  1.113885 -0.967471 -0.247797   \n",
      "3  1.601727 -0.451642 -0.644364  ... -0.129641  1.113885 -0.967471 -0.247797   \n",
      "4 -0.890458 -0.451642  1.551918  ... -0.129641 -0.897758  1.033623 -0.247797   \n",
      "\n",
      "         16        17        18        19        20        21  \n",
      "0  0.935932 -0.824958 -0.542326  2.821872 -0.274874 -0.145248  \n",
      "1 -1.068454 -0.824958 -0.542326 -0.354375  3.638034 -0.145248  \n",
      "2 -1.068454  1.212183  1.843909 -0.354375 -0.274874 -0.145248  \n",
      "3 -1.068454  1.212183  1.843909 -0.354375 -0.274874 -0.145248  \n",
      "4  0.935932 -0.824958  1.843909 -0.354375 -0.274874 -0.145248  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the preprocessed training data\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524590163934426\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84        28\n",
      "           1       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  5]\n",
      " [ 4 29]]\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for Logistic Regression...\n",
      "Best parameters for Logistic Regression: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Best cross-validated score: 0.8433673469387755\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best cross-validated score: 0.810204081632653\n",
      "\n",
      "Tuning hyperparameters for SVC...\n",
      "Best parameters for SVC: {'C': 1, 'kernel': 'linear'}\n",
      "Best cross-validated score: 0.8474489795918367\n",
      "\n",
      "Tuning hyperparameters for KNN...\n",
      "Best parameters for KNN: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Best cross-validated score: 0.8227040816326531\n",
      "\n",
      "Evaluating Logistic Regression on the test set...\n",
      "F1 Score: 0.87\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82        28\n",
      "           1       0.82      0.94      0.87        33\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.86      0.84      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  7]\n",
      " [ 2 31]]\n",
      "--------------------------------------------------\n",
      "Evaluating Random Forest on the test set...\n",
      "F1 Score: 0.79\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.71        28\n",
      "           1       0.74      0.85      0.79        33\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.76      0.75      0.75        61\n",
      "weighted avg       0.76      0.75      0.75        61\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18 10]\n",
      " [ 5 28]]\n",
      "--------------------------------------------------\n",
      "Evaluating SVC on the test set...\n",
      "F1 Score: 0.85\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78        28\n",
      "           1       0.79      0.91      0.85        33\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.83      0.81      0.81        61\n",
      "weighted avg       0.83      0.82      0.82        61\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  8]\n",
      " [ 3 30]]\n",
      "--------------------------------------------------\n",
      "Evaluating KNN on the test set...\n",
      "F1 Score: 0.87\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83        28\n",
      "           1       0.83      0.91      0.87        33\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.86      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22  6]\n",
      " [ 3 30]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define models and hyperparameter grids for tuning\n",
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"solver\": [\"lbfgs\", \"liblinear\"]}\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5, 10]}\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(random_state=42),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning and evaluate each model\n",
    "best_models = {}\n",
    "for name, model_data in models.items():\n",
    "    print(f\"Tuning hyperparameters for {name}...\")\n",
    "    grid = GridSearchCV(model_data[\"model\"], model_data[\"params\"], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"Best cross-validated score: {grid.best_score_}\\n\")\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "for name, model in best_models.items():\n",
    "    print(f\"Evaluating {name} on the test set...\")\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
